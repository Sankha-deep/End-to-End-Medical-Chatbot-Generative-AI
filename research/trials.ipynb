{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9897f0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\chatbot\\\\End-to-End-Medical-Chatbot-Generative-AI\\\\research'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "923e6370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40f2bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c71639fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e92d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_single_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_single_pdf(r'D:\\chatbot\\End-to-End-Medical-Chatbot-Generative-AI\\Data\\clinicians-guide-to-cognitive-rehabilitation-in-mild-traumatic-brain-injury.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c160c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c583dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19bff621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 561\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adfd2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed38f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "323f8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade langchain langchain-community sentence-transformers huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8757885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a4f6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2423c09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ba8ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4818212b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medicalbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medicalbot-1kb2huf.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bc626f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aeb7e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9833b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d585db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58bdbea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (0.3.24)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (0.32.4)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.32.6-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (0.3.64)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-community) (3.12.12)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sankha\\anaconda3\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "Downloading huggingface_hub-0.32.6-py3-none-any.whl (512 kB)\n",
      "Installing collected packages: huggingface-hub, langchain-core, langchain-community\n",
      "\n",
      "  Attempting uninstall: huggingface-hub\n",
      "\n",
      "    Found existing installation: huggingface-hub 0.32.4\n",
      "\n",
      "    Uninstalling huggingface-hub-0.32.4:\n",
      "\n",
      "      Successfully uninstalled huggingface-hub-0.32.4\n",
      "\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "  Attempting uninstall: langchain-core\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "    Found existing installation: langchain-core 0.3.64\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "    Uninstalling langchain-core-0.3.64:\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "      Successfully uninstalled langchain-core-0.3.64\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "  Attempting uninstall: langchain-community\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "    Found existing installation: langchain-community 0.3.24\n",
      "   ------------- -------------------------- 1/3 [langchain-core]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "    Uninstalling langchain-community-0.3.24:\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "      Successfully uninstalled langchain-community-0.3.24\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   -------------------------- ------------- 2/3 [langchain-community]\n",
      "   ---------------------------------------- 3/3 [langchain-community]\n",
      "\n",
      "Successfully installed huggingface-hub-0.32.6 langchain-community-0.3.25 langchain-core-0.3.65\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain langchain-community sentence-transformers huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "OPENROUTER_API_KEY=os.environ.get('OPENROUTER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  # Install with: pip install python-dotenv\n",
    "\n",
    "# Load keys from .env file\n",
    "load_dotenv()  \n",
    "\n",
    "# Access keys directly\n",
    "pinecone_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "openrouter_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Verify keys exist\n",
    "if not openai_key:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c304fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys from pre-configured system environment variables\n",
    "os.environ[\"PINECONE_API_KEY\"] = os.environ.get(\"PINECONE_API_KEY\", \"\")\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = os.environ.get(\"OPENROUTER_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2423702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ff1cb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x23567e8d8a0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be491c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b706b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3aeb95a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c0705383-55a6-4500-a87d-2b7bede5b444', metadata={'creationdate': '2016-12-30T07:22:15+00:00', 'creator': 'Word', 'keywords': '', 'moddate': '2017-07-03T08:28:11-04:00', 'page': 12.0, 'page_label': '13', 'producer': 'Mac OS X 10.11.6 Quartz PDFContext', 'source': 'D:\\\\chatbot\\\\End-to-End-Medical-Chatbot-Generative-AI\\\\Data\\\\clinicians-guide-to-cognitive-rehabilitation-in-mild-traumatic-brain-injury.pdf', 'title': 'Clinician’s Guide to Cognitive Rehabilitation in Mild Traumatic Brain Injury: Application for Military Service Members and Veterans', 'total_pages': 107.0, 'uploaddate': '7/3/2017'}, page_content='A\\tlarge\\tbody\\tof\\tliterature\\taCributes\\tpersistent\\tcogni.ve\\tsymptoms\\taTer\\tmTBI\\tto\\tproblems\\t\\t\\nsuch\\tas\\theadaches,\\tpain,\\tsleep\\tdisturbance,\\tdepression,\\tpost-deployment\\tstress,\\tor\\tstress\\t\\ndisorders.\\tIt\\tis\\toTen\\tnot\\tpossible\\tto\\taccurately\\tiden.fy\\thow\\tmuch\\teach\\tcondi.on\\tcontributes\\t\\nto\\tongoing\\tcogni.ve\\tdiﬃcul.es.\\tRegardless\\tof\\tthe\\tlack\\tof\\tclarity\\tabout\\tthe\\te.ology\\tof\\tthe\\t\\nproblems,\\tthe\\tclinician\\tshould\\tmove\\tbeyond\\tsymptom\\taCribu.on\\tand\\thelp\\tthe\\tSM/V\\timprove'),\n",
       " Document(id='01915e05-a305-4553-a1ad-7a58d4d11376', metadata={'creationdate': '2016-12-30T07:22:15+00:00', 'creator': 'Word', 'keywords': '', 'moddate': '2017-07-03T08:28:11-04:00', 'page': 6.0, 'page_label': '7', 'producer': 'Mac OS X 10.11.6 Quartz PDFContext', 'source': 'D:\\\\chatbot\\\\End-to-End-Medical-Chatbot-Generative-AI\\\\Data\\\\clinicians-guide-to-cognitive-rehabilitation-in-mild-traumatic-brain-injury.pdf', 'title': 'Clinician’s Guide to Cognitive Rehabilitation in Mild Traumatic Brain Injury: Application for Military Service Members and Veterans', 'total_pages': 107.0, 'uploaddate': '7/3/2017'}, page_content='confronting military personnel and has been deemed the “signature injury” of combat in \\nsupport of Operation Enduring Freedom (OEF) and Operation Iraqi Freedom (OIF). Mild TBI, \\nalso called concussion, may occur in as many as 20% of combatants .\\n1,2,3 Mild TBI is associated \\nwith a physical force to the head with resulting alteration in consciousness. Combat assaults \\ninvolving explosive devices account for a large percentage of combat related inju ries and'),\n",
       " Document(id='080c14b9-f280-40da-a7a8-46304cc2af3a', metadata={'creationdate': '2016-12-30T07:22:15+00:00', 'creator': 'Word', 'keywords': '', 'moddate': '2017-07-03T08:28:11-04:00', 'page': 68.0, 'page_label': '69', 'producer': 'Mac OS X 10.11.6 Quartz PDFContext', 'source': 'D:\\\\chatbot\\\\End-to-End-Medical-Chatbot-Generative-AI\\\\Data\\\\clinicians-guide-to-cognitive-rehabilitation-in-mild-traumatic-brain-injury.pdf', 'title': 'Clinician’s Guide to Cognitive Rehabilitation in Mild Traumatic Brain Injury: Application for Military Service Members and Veterans', 'total_pages': 107.0, 'uploaddate': '7/3/2017'}, page_content='sun when driving to and from campus, fluorescent lights in the classroom, glare from the \\ncomputer screen). Based upon this finding, the clinician contacted his primary care physician to \\ndiscuss a referral for consultation with an eye specialist. After his evaluation, CH’s treatment \\nplan was modified to incorporate recommendations to reduce eyestrain and manage light \\nsensitivity. \\n \\nmTBI\\tRehabilitation\\tToolkit  resource: Chapter 4 - Section on “Glare/Photophobia Management” (pp. \\n139-140)')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "536b4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d680787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d17004e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fb9ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl (18.5 MB)\n",
      "   ---------------------------------------- 0.0/18.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.9/18.5 MB 24.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 5.2/18.5 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.6/18.5 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 9.7/18.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 11.5/18.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.2/18.5 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.8/18.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.5/18.5 MB 12.1 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8d197a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \" \".join([page.get_text() for page in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8892c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=1000):\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0792eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_pdf_text(\"D:\\chatbot\\End-to-End-Medical-Chatbot-Generative-AI\\Data\\clinicians-guide-to-cognitive-rehabilitation-in-mild-traumatic-brain-injury.pdf\")\n",
    "chunks = chunk_text(pdf_text)\n",
    "\n",
    "# Use only the first chunk or combine multiple if needed\n",
    "context = chunks[0]\n",
    "\n",
    "data = {\n",
    "    \"model\": \"mistralai/mistral-7b-instruct:free\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful assistant. Only use the following context to answer:\\n\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Transition to Self-Management\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e323ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The \"Transition to Self-Management\" is not explicitly defined in the provided context. However, given the context of the Clinician's Guide to Cognitive Rehabilitation in Mild Traumatic Brain Injury, it is likely that Transition to Self-Management refers to the process where the individuals with mild traumatic brain injury (mTBI) are helped to take on greater responsibility for managing their cognitive impairments and recovery, with reduced supervision from healthcare professionals. This process involves teaching them strategies and skills that enable them to effectively self-manage their condition, adapt to challenges, and maximize their independence.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"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\"  # Your OpenRouter API key\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"https://chat.openai.com\",\n",
    "    \"X-Title\": \"MyApp\"\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
